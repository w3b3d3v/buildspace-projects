### Hide your unique subject identifier

It‚Äôs kinda wack that your users have to type ‚Äúabraza‚Äù to generate prompts of you. This is an easy fix! Just use the Javascript `replace()` function to hide it from them!

Right before you make the API call in `index.js` inside `generateAction` , put in something like this:

```jsx
const finalInput = input.replace(/raza/gi, 'abraza');

const response = await fetch('/api/generate', {
  method: 'POST',
  headers: {
    'Content-Type': 'image/jpeg',
  },
  body: JSON.stringify({ input: finalInput }),
});
```

`replace` takes in a regular expression, that‚Äôs what the `/raza/gi` fanciness is. You can use something like [AutoRegex](https://www.autoregex.xyz/) which is a GPT powered regex translator if you have various spellings or nicknames! Most of the time, `replace("name", "unique_ting")` will work just fine.

You can read up more about replace [here](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/replace), it‚Äôs pretty simple, and regular expressions [here](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp) (they‚Äôre not simple at all üíÄ)

### Generate variations of avatars with your prompt

You may have noticed when you send your prompt in the POST request, you will get exactly the same image every time you POST that prompt. This is fine, however if you want to get different variations from your prompt, you can add a new header `x-use-cache`: `false` to the headers of your POST request.

In `api/generate.js` inside `generateAction`, add the header `x-use-cache` in the `fetch` call and set it to `false`:

```jsx
const response = await fetch(
    `https://api-inference.huggingface.co/models/buildspace/ai-avatar-generator`,
    {
        headers: {
            Authorization: `Bearer ${process.env.HF_AUTH_KEY}`,
            'Content-Type': 'application/json',
            'x-use-cache': 'false'
        },
        method: 'POST',
        body: JSON.stringify({
            inputs: input,
        }),
    }
);
```

This will prevent using the previous image you generated, and allows us to fetch a new image from the Hugging Face API endpoint rather than fetching the image you generated previously from the cache.

Now generate an avatar with a prompt in the UI and generate another with the same prompt and see the variations!

### Give your users some fancy prompts

Shall we bestow some of your magic onto your users? They‚Äôll get much better results if you give them some prompts they can modify. They probably don‚Äôt know who all these fancy artists are, so let‚Äôs build some buttons that fill these prompts in!

I‚Äôm not gonna walk you through this, but really all this would be is a set of buttons that update the value of `input` in `index.js` to preset prompts. 

While you‚Äôre at it, might as well split up the input bar into the core 4 pieces - artist, medium, vibe, descriptors. This will train the users ***how*** to write good prompts without them even realising!

So you gotta build two things - 

1. A few buttons that auto populate the prompt input field with preset prompts
2. Four fields for each minor 

Here‚Äôs a messy mock-up of what this might look like:

![https://hackmd.io/_uploads/BJ_I96Vqo.png](https://hackmd.io/_uploads/BJ_I96Vqo.png)

All you‚Äôd have to do is [`concat`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/concat) the fields together for the final prompt. Ezpz. 

These two bits are really important! Most devs don‚Äôt really think about how simple tweaks like these impact the user experience. By being explicit about what the user needs to describe, everyone from your grandma to your dog will be able to generate good stuff.

**Designing simple products takes more work than messy, complicated products.**

My design has lots of room for improvement. Should the artist field be a dropdown instead? Wtf is a descriptor? What do vibes even look like? 

I‚Äôll leave it up to you to take it further, maybe store generated images and their prompts in a DB so your users can look at old results while they wait for new images to be generated? That‚Äôd be pretty cool!

### How do I let other people generate avatars of their own?

The big money maker. Getting people to generate their own images. There‚Äôs no way around training models - you‚Äôll need to use Dreambooth to created a customised model **for each person**. This **will** cost money. The way the big players like Lensa and AvatarAI do it is renting bare metal GPUs via cloud providers like AWS or GCP.

Their entire operation is a programmatic way of the manual parts you did in this build.

If I had to guess, their flow is probably something like:

1. Get 5-10 images from user
2. Process images (resize, remove background)
3. Tune Stable Diffusion model with GPUs
4. Use predefined prompts to generate 50-100 images
5. Send user images, maybe delete their model

All of this is simple-ish to do programmatically. The trick here is getting GPUs for as cheap as possible. Idk if you can get GPUs as cheap as Lensa ($3.49 for 100 avatars lol), but the opportunity here is in steps #2 and #3 I think. 

There are awesome platforms out there that help you build these flows for a cheaper price such as, [banana.dev](https://banana.dev). Make sure to claim your NFT at the end to get some insane credits from them. Maybe thats all you need to get your business going ü§ò.

## Deploy with Railway
**GTFOL: Let‚Äôs go to prod.**

It‚Äôs time to [gtfol](https://www.urbandictionary.com/define.php?term=GTFOL&utm_source=buildspace.so&utm_medium=buildspace_project).

We don‚Äôt want to just stay on localhost, after all. That‚Äôd be boring! The whole point of this app is to let your friends and family create alternate realities with you.

Deploying a NextJS app has gotten **SUPER** easy - this should just take a few minutes ‚Äî and then you‚Äôll have a link to your creation you can share with the world.

Check out this vid to find out what you‚Äôll need to do here

[https://vimeo.com/786802338](https://vimeo.com/786802338)
